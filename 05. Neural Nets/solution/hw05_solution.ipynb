{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw05_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qp0H_zUQuu_"
      },
      "source": [
        "# Нейронные сети\n",
        "__Суммарное количество баллов: 10__\n",
        "\n",
        "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
        "\n",
        "__Тема письма: `[HSE][ML][MS][HW05] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
        "\n",
        "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ezVRf3QuvA"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "from sklearn.datasets import make_blobs, make_moons\n",
        "from typing import List, NoReturn\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfDPH_LQuvF"
      },
      "source": [
        "### Задание 1 (3 балла)\n",
        "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
        "\n",
        "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
        "\n",
        "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
        "\n",
        "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
        "\n",
        "\n",
        "#### Методы\n",
        "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
        "\n",
        "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
        "\n",
        "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFLlHqaYbgC"
      },
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Абстрактный класс.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def backward(self, d):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def update(self, alpha):\n",
        "        pass\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYS2gE4PYepZ"
      },
      "source": [
        "\n",
        "class Linear(Module):\n",
        "    \"\"\"\n",
        "    Линейный полносвязный слой.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_features : int\n",
        "            Размер входа.\n",
        "        out_features : int\n",
        "            Размер выхода.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        W и b инициализируются случайно.\n",
        "        \"\"\"\n",
        "        std = in_features ** 0.5\n",
        "        self.W = np.random.randn(out_features, in_features) / std\n",
        "        self.b = np.random.randn(out_features)\n",
        "        self.input = None\n",
        "        self.W_grad = None\n",
        "        self.b_grad = None\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Wx + b.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "            То есть, либо x вектор с in_features элементов,\n",
        "            либо матрица размерности (batch_size, in_features).\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя.\n",
        "            Либо вектор с out_features элементами,\n",
        "            либо матрица размерности (batch_size, out_features)\n",
        "\n",
        "        \"\"\"\n",
        "        self.input = copy.deepcopy(x)\n",
        "        return np.array(x).dot(self.W.T) + self.b\n",
        "\n",
        "    def backward(self, d: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        self.W_grad = np.array([np.outer(a, b) for a, b in zip(self.input, d)])\n",
        "        self.b_grad = copy.deepcopy(d)\n",
        "        return d.dot(self.W)\n",
        "\n",
        "    def update(self, alpha: float) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обновляет W и b с заданной скоростью обучения.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha : float\n",
        "            Скорость обучения.\n",
        "        \"\"\"\n",
        "        delta = self.W_grad.mean(axis=0) * alpha\n",
        "        self.W += delta.T\n",
        "        delta = self.b_grad.mean(axis=0) * alpha\n",
        "        self.b += delta.T"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hkbnD1QuvG"
      },
      "source": [
        "class ReLU(Module):\n",
        "    \"\"\"\n",
        "    Слой, соответствующий функции активации ReLU.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = max(0, x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        self.input = copy.deepcopy(x)\n",
        "        return np.maximum(0, self.input)\n",
        "\n",
        "    def backward(self, d) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        mask = self.input.reshape(-1) > 0\n",
        "        grad = np.zeros(d.shape)\n",
        "        grad.reshape(-1)[mask] = d.reshape(-1)[mask]\n",
        "        return grad\n",
        "\n",
        "\n",
        "class Softmax(Module):\n",
        "    \"\"\"\n",
        "    Слой, соответствующий функции активации Softmax.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.activation = None\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Softmax(x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        x_exp_normalized = np.exp(x - np.max(x))\n",
        "        self.activation = x_exp_normalized / np.sum(x_exp_normalized, axis=-1, keepdims=True)\n",
        "        return self.activation\n",
        "\n",
        "    def backward(self, d) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        return d * self.activation * (1 - self.activation)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_ip_h8QuvJ"
      },
      "source": [
        "### Задание 2 (2 балла)\n",
        "Теперь сделаем саму нейронную сеть.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
        "\n",
        "#### Параметры конструктора\n",
        "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
        "\n",
        "`epochs` - количество эпох обучения\n",
        "\n",
        "`alpha` - скорость обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_JFCizKQuvK"
      },
      "source": [
        "class MLPClassifier:\n",
        "    def __init__(self, modules: List[Module], epochs: int = 40, alpha: float = 0.01):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        modules : List[Module]\n",
        "            Список, состоящий из ранее реализованных модулей и\n",
        "            описывающий слои нейронной сети.\n",
        "            В конец необходимо добавить Softmax.\n",
        "        epochs : int\n",
        "            Количество эпох обучения\n",
        "        alpha : float\n",
        "            Скорость обучения.\n",
        "        \"\"\"\n",
        "        self.modules = modules + [Softmax()]\n",
        "        self.epochs = epochs\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray, batch_size=32) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обучает нейронную сеть заданное число эпох.\n",
        "        В каждой эпохе необходимо использовать cross-entropy loss для обучения,\n",
        "        а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для обучения.\n",
        "        y : np.ndarray\n",
        "            Вектор меток классов для данных.\n",
        "        batch_size : int\n",
        "            Размер батча.\n",
        "        \"\"\"\n",
        "        n_steps = int(np.ceil(len(X) / batch_size))\n",
        "        classes = np.unique(y)\n",
        "        y = np.array([[int(yy == c) for c in classes]\n",
        "                      for yy in y])\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            indices = np.arange(X.shape[0])\n",
        "            np.random.shuffle(indices)\n",
        "            X_shuffled, y_shuffled = X[indices], y[indices]\n",
        "            for i in range(n_steps):\n",
        "                l, r = i * batch_size, min((i + 1) * batch_size, len(X_shuffled))\n",
        "                X_batch, y_batch = X_shuffled[l:r], y_shuffled[l:r]\n",
        "                for m in self.modules:\n",
        "                    X_batch = m.forward(X_batch)\n",
        "                d = y_batch / X_batch\n",
        "                for m in reversed(self.modules):\n",
        "                    d = m.backward(d)\n",
        "                for m in self.modules:\n",
        "                    m.update(self.alpha)\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказывает вероятности классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Предсказанные вероятности классов для всех элементов X.\n",
        "            Размерность (X.shape[0], n_classes)\n",
        "\n",
        "        \"\"\"\n",
        "        for m in self.modules:\n",
        "            X = m.forward(X)\n",
        "        return X\n",
        "\n",
        "    def predict(self, X) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказывает метки классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Вектор предсказанных классов\n",
        "\n",
        "        \"\"\"\n",
        "        p = self.predict_proba(X)\n",
        "        return np.argmax(p, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onDymYQXQuvN"
      },
      "source": [
        "p = MLPClassifier([\n",
        "    Linear(4, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 2)\n",
        "])\n",
        "\n",
        "X = np.random.randn(50, 4)\n",
        "y = np.array([(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X])\n",
        "p.fit(X, y, batch_size=32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C1EIsDqQuvQ"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
        "\n",
        "#### Оценка\n",
        "Accuracy на первом датасете больше 0.85 - +1 балл\n",
        "\n",
        "Accuracy на втором датасете больше 0.85 - +1 балл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UAgXTcQuvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959638fa-c560-4a75-da3b-664caa6bd532"
      },
      "source": [
        "X, y = make_moons(400, noise=0.075)\n",
        "X_test, y_test = make_moons(400, noise=0.075)\n",
        "\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([\n",
        "                       Linear(2, 16),\n",
        "                       ReLU(),\n",
        "                       Linear(16, 16),\n",
        "                       ReLU(),\n",
        "                       Linear(16, 2),\n",
        "                       ],\n",
        "                      alpha=0.002)\n",
        "\n",
        "    p.fit(X, y, batch_size=32)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMDJM4qFQuvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d3d4ea-6cf0-4bef-c5c9-5157683dd58a"
      },
      "source": [
        "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([\n",
        "                       Linear(2, 16),\n",
        "                       ReLU(),\n",
        "                       Linear(16, 16),\n",
        "                       ReLU(),\n",
        "                       Linear(16, 3),\n",
        "                       ], \n",
        "                       alpha=0.002)\n",
        "    p.fit(X, y,  batch_size=32)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPbVTFnMQuvW"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0mJLu-QuvX"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUC_QqpAQuva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89a4c77-1636-4f8a-f5b2-87a45847eb40"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "t = transforms.ToTensor()\n",
        "\n",
        "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
        "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
        "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmpjcFfQuvd"
      },
      "source": [
        "### Задание 4 (3 балла)\n",
        "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
        "\n",
        "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
        "\n",
        "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
        "\n",
        "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sRmTKwKQuve"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1), \n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride=2), \n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(800, 256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self._layers(x)\n",
        "        \n",
        "def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n",
        "    \"\"\"\n",
        "    Cчитает cross-entropy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : torch.Tensor\n",
        "        Данные для обучения.\n",
        "    y : torch.Tensor\n",
        "        Метки классов.\n",
        "    model : Model\n",
        "        Модель, которую будем обучать.\n",
        "\n",
        "    \"\"\"\n",
        "    preds = model(X)\n",
        "    return F.cross_entropy(preds, y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsLmkUqQuvh"
      },
      "source": [
        "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5G8iMCeQuvh"
      },
      "source": [
        "def train(model, epochs=100):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for i in tqdm(range(1, epochs + 1)):\n",
        "        #Train\n",
        "        loss_mean = 0\n",
        "        elements = 0\n",
        "        for X, y in iter(train_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        train_losses.append(loss_mean / elements)\n",
        "        #Test\n",
        "        loss_mean = 0 \n",
        "        elements = 0\n",
        "        for X, y in iter(test_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        test_losses.append(loss_mean / elements)\n",
        "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
        "    return train_losses, test_losses"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmD9eWJOQuvl",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b48f459-30f7-454a-b01a-1e4e8e6cbaea"
      },
      "source": [
        "model = Model().to(device)\n",
        "train_l, test_l = train(model, epochs=40)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▎         | 1/40 [00:37<24:05, 37.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train loss 2.0387307322311403 | Test loss 1.848647530555725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 2/40 [01:13<23:20, 36.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Train loss 1.7663790322494506 | Test loss 1.6782336778640747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 3/40 [01:51<23:02, 37.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Train loss 1.6577338019180299 | Test loss 1.6034801496505737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 4/40 [02:28<22:18, 37.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Train loss 1.5920847072219848 | Test loss 1.5551266328811646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 5/40 [03:05<21:38, 37.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Train loss 1.550633854408264 | Test loss 1.5345998640060425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 6/40 [03:42<20:57, 37.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | Train loss 1.4923401596069337 | Test loss 1.480566697883606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 7/40 [04:19<20:21, 37.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 | Train loss 1.4569531615066529 | Test loss 1.4597939905166626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 8/40 [04:56<19:47, 37.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 | Train loss 1.423763810081482 | Test loss 1.4276972282409668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 9/40 [05:34<19:12, 37.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 | Train loss 1.3952356734848022 | Test loss 1.4007784023284913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 10/40 [06:10<18:32, 37.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Train loss 1.3670640897750854 | Test loss 1.3840372968673706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 11/40 [06:47<17:53, 37.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | Train loss 1.3364675966644286 | Test loss 1.338543501663208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 12/40 [07:24<17:15, 36.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | Train loss 1.309109283065796 | Test loss 1.3244517948150634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 13/40 [08:01<16:37, 36.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | Train loss 1.2977857913970947 | Test loss 1.350508225440979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 14/40 [08:38<16:01, 36.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 | Train loss 1.268220912437439 | Test loss 1.2937687831878661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 15/40 [09:15<15:24, 36.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | Train loss 1.253973945388794 | Test loss 1.3158726655960082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 16/40 [09:54<15:00, 37.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | Train loss 1.2311580986404418 | Test loss 1.2685939353942872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 17/40 [10:31<14:21, 37.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | Train loss 1.2268989865493773 | Test loss 1.274601349067688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 18/40 [11:08<13:41, 37.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | Train loss 1.1892979219436646 | Test loss 1.2375548099517821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 19/40 [11:45<13:02, 37.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | Train loss 1.1893861735153197 | Test loss 1.2363566387176514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 20/40 [12:22<12:23, 37.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | Train loss 1.1557021390533446 | Test loss 1.2341110359191894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 21/40 [12:59<11:45, 37.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 | Train loss 1.1413165069198608 | Test loss 1.2173389230728149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 22/40 [13:36<11:07, 37.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 | Train loss 1.1256624367523194 | Test loss 1.2064126092910767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 23/40 [14:14<10:30, 37.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 | Train loss 1.1211447623825073 | Test loss 1.2081150901794433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 24/40 [14:50<09:52, 37.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 | Train loss 1.0993610527801514 | Test loss 1.1963403400421142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 25/40 [15:28<09:16, 37.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 | Train loss 1.0703229863357544 | Test loss 1.1905911115646362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 26/40 [16:05<08:40, 37.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 | Train loss 1.0643982984924316 | Test loss 1.1805892906188964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 27/40 [16:42<08:04, 37.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 | Train loss 1.0506810660552979 | Test loss 1.2158882144927978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 28/40 [17:20<07:27, 37.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 | Train loss 1.0439652800369263 | Test loss 1.1627860929489136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 29/40 [17:57<06:50, 37.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 | Train loss 1.0218621856689454 | Test loss 1.1628093618392945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 30/40 [18:35<06:13, 37.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 | Train loss 1.0143832834243773 | Test loss 1.1507949089050293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 31/40 [19:12<05:36, 37.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 | Train loss 0.9906645786476135 | Test loss 1.1431089763641358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 32/40 [19:49<04:58, 37.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 | Train loss 0.980725334815979 | Test loss 1.1703273338317872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 33/40 [20:27<04:21, 37.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 | Train loss 0.9613366938972473 | Test loss 1.1513035066604613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 34/40 [21:04<03:43, 37.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 | Train loss 0.9493982503509522 | Test loss 1.1344126607894898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 35/40 [21:41<03:05, 37.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 | Train loss 0.9442788737869263 | Test loss 1.1811286767959595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 36/40 [22:18<02:28, 37.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 | Train loss 0.9316654389953614 | Test loss 1.15242948513031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 37/40 [22:54<01:50, 36.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 | Train loss 0.913840373840332 | Test loss 1.1346906316757202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 38/40 [23:31<01:13, 36.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 | Train loss 0.8956435733795166 | Test loss 1.140757343673706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 39/40 [24:07<00:36, 36.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 | Train loss 0.8877619599533081 | Test loss 1.1414508422851561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [24:44<00:00, 37.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 | Train loss 0.868270841293335 | Test loss 1.1366325119018554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJNAuHjNQuvn"
      },
      "source": [
        "Построим график функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6OEGqriQuvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "56443161-61a2-4a3f-9268-3ed9dc549166"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
        "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miUxg0bDQuvs"
      },
      "source": [
        "И, наконец, посчитаем метрики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSOJFI8Quvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b899b2-ec1e-439a-fd72-16b051045bcc"
      },
      "source": [
        "true_positive = np.zeros(10)\n",
        "true_negative = np.zeros(10)\n",
        "false_positive = np.zeros(10)\n",
        "false_negative = np.zeros(10)\n",
        "accuracy = 0\n",
        "ctn = 0\n",
        "for X, y in iter(test_loader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X).max(dim=1)[1]\n",
        "    for i in range(10):\n",
        "        for pred, real in zip(y_pred, y):\n",
        "            if real == i:\n",
        "                if pred == real:\n",
        "                    true_positive[i] += 1\n",
        "                else:\n",
        "                    false_negative[i] += 1\n",
        "            else:\n",
        "                if pred == i:\n",
        "                    false_positive[i] += 1\n",
        "                else:\n",
        "                    true_negative[i] += 1\n",
        "            \n",
        "    accuracy += torch.sum(y_pred == y).item()\n",
        "    ctn += len(y)\n",
        "print(\"Overall accuracy\", accuracy / ctn)\n",
        "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
        "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
        "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
        "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy 0.6082\n",
            "Precision [0.63729128 0.70387454 0.52997275 0.44216867 0.54205607 0.50997151\n",
            " 0.62489762 0.64874884 0.73513514 0.65246854]\n",
            "Recall [0.687 0.763 0.389 0.367 0.522 0.537 0.763 0.7   0.68  0.674]\n",
            "Mean Precision 0.6026584970164894\n",
            "Mean Recall 0.6082000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKA-j4rIQuvv"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}